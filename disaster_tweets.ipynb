{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef182c77",
   "metadata": {},
   "source": [
    "# Disaster Tweet Mini-Project\n",
    "Zhen Lian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d534b9",
   "metadata": {},
   "source": [
    "## Overview\n",
    "The goal of this project is to build a classifier which identifies tweets related to disasters. The dataset used in this project is from Kaggle competition \"Natural Language Processing with Disaster Tweets\" (https://www.kaggle.com/c/nlp-getting-started/overview). Link to GitHub repository: https://github.com/zlianrpi/disaster-tweet-mini-project.git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6924893",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "First let us load the data into a DataFrame and inspect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5477a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4079cdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0950ab69",
   "metadata": {},
   "source": [
    "Checking the information about the dataframe and visualizing the lengths of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7593a864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df12ba28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7613.000000\n",
       "mean      101.037436\n",
       "std        33.781325\n",
       "min         7.000000\n",
       "25%        78.000000\n",
       "50%       107.000000\n",
       "75%       133.000000\n",
       "max       157.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_lengths = df['text'].str.len()\n",
    "plt.hist(text_lengths)\n",
    "plt.title('Histogram of text length')\n",
    "text_lengths.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f7e9b5",
   "metadata": {},
   "source": [
    "The dataset contains information about 7613 tweets. Text and label contain no null values. Other columns contain some null values. Text length has a mean of 101 and a standard deviation of 34. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e383a32",
   "metadata": {},
   "source": [
    "Next let us take a random sample from the dataset and check the format of the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d011cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>454</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>Wrigley Field</td>\n",
       "      <td>@KatieKatCubs you already know how this shit g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>7086</td>\n",
       "      <td>meltdown</td>\n",
       "      <td>Two Up Two Down</td>\n",
       "      <td>@LeMaireLee @danharmon People Near Meltdown Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>762</td>\n",
       "      <td>avalanche</td>\n",
       "      <td>Score Team Goals Buying @</td>\n",
       "      <td>1-6 TIX Calgary Flames vs COL Avalanche Presea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>9094</td>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>Roadside</td>\n",
       "      <td>If you ever think you running out of choices i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>1160</td>\n",
       "      <td>blight</td>\n",
       "      <td>Laventillemoorings</td>\n",
       "      <td>If you dotish to blight your car go right ahea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>1973</td>\n",
       "      <td>bush%20fires</td>\n",
       "      <td>iPhone: -27.499212,153.011072</td>\n",
       "      <td>@marcoarment Middle of winter in Sydney we hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7337</th>\n",
       "      <td>10503</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>Riverside, California.</td>\n",
       "      <td>Is LA at Risk for a Giant Wildfire? - Which Wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>1924</td>\n",
       "      <td>burning%20buildings</td>\n",
       "      <td>St Charles, MD</td>\n",
       "      <td>I'm mentally preparing myself for a bomb ass s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>7677</td>\n",
       "      <td>panic</td>\n",
       "      <td>518 åá NY</td>\n",
       "      <td>Savs contact fell out but she was convinced it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id              keyword                       location  \\\n",
       "311     454           armageddon                  Wrigley Field   \n",
       "4970   7086             meltdown                Two Up Two Down   \n",
       "527     762            avalanche      Score Team Goals Buying @   \n",
       "6362   9094       suicide%20bomb                       Roadside   \n",
       "800    1160               blight            Laventillemoorings    \n",
       "...     ...                  ...                            ...   \n",
       "1369   1973         bush%20fires  iPhone: -27.499212,153.011072   \n",
       "7337  10503             wildfire         Riverside, California.   \n",
       "7612  10873                  NaN                            NaN   \n",
       "1332   1924  burning%20buildings                 St Charles, MD   \n",
       "5379   7677                panic                      518 åá NY   \n",
       "\n",
       "                                                   text  target  \n",
       "311   @KatieKatCubs you already know how this shit g...       0  \n",
       "4970  @LeMaireLee @danharmon People Near Meltdown Co...       0  \n",
       "527   1-6 TIX Calgary Flames vs COL Avalanche Presea...       0  \n",
       "6362  If you ever think you running out of choices i...       0  \n",
       "800   If you dotish to blight your car go right ahea...       0  \n",
       "...                                                 ...     ...  \n",
       "1369  @marcoarment Middle of winter in Sydney we hav...       1  \n",
       "7337  Is LA at Risk for a Giant Wildfire? - Which Wa...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "1332  I'm mentally preparing myself for a bomb ass s...       0  \n",
       "5379  Savs contact fell out but she was convinced it...       0  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(100, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5234b60",
   "metadata": {},
   "source": [
    "It seems that the text data in the dataset contains some useless feature, including patterns like \"@user_name\", web links and special characters. Here I removed those words with regular expression. I also converted all capital letters into lowercase so that the model is not case-sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "347c35eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>two giant cranes holding a bridge collapse int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>the out of control wild fires in california ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>m194 0104 utc5km s of volcano hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>police investigating after an ebike collided w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>the latest more homes razed by northern califo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                         processed_text  \n",
       "0     our deeds are the reason of this earthquake ma...  \n",
       "1                 forest fire near la ronge sask canada  \n",
       "2     all residents asked to shelter in place are be...  \n",
       "3     13000 people receive wildfires evacuation orde...  \n",
       "4     just got sent this photo from ruby alaska as s...  \n",
       "...                                                 ...  \n",
       "7608  two giant cranes holding a bridge collapse int...  \n",
       "7609  the out of control wild fires in california ev...  \n",
       "7610              m194 0104 utc5km s of volcano hawaii   \n",
       "7611  police investigating after an ebike collided w...  \n",
       "7612  the latest more homes razed by northern califo...  \n",
       "\n",
       "[7613 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text'] = df['text'].str.replace('@\\w* ', '', case=False, regex=True)\n",
    "df['processed_text'] = df['processed_text'].str.replace('http[^\\s]*', '', case=False, regex=True)\n",
    "df['processed_text'] = df['processed_text'].str.replace('[^\\w\\s]', '', regex=True)\n",
    "df['processed_text'] = df['processed_text'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354461f6",
   "metadata": {},
   "source": [
    "Here is the code to split the data into train and validation set and load them into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7cffc12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2ece5896",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(df_train['processed_text'])\n",
    "y_train = tf.convert_to_tensor(df_train['target'])\n",
    "X_val = tf.convert_to_tensor(df_val['processed_text'])\n",
    "y_val = tf.convert_to_tensor(df_val['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3636e15",
   "metadata": {},
   "source": [
    "## Model training and evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0656789f",
   "metadata": {},
   "source": [
    "First we need to define a preprocessing layer which converts the text data into word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e7080c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35977e17",
   "metadata": {},
   "source": [
    "Checking the most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "84c85c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is', 'for',\n",
       "       'on', 'you', 'my', 'it', 'with', 'that', 'at', 'by', 'this',\n",
       "       'from', 'be', 'are', 'have', 'was', 'as', 'up', 'like', 'just',\n",
       "       'me', 'so', 'but', 'im', 'amp', 'not', 'your', 'has', 'out', 'its',\n",
       "       'will', 'after', 'no', 'if', 'all', 'fire', 'when', 'an', 'we',\n",
       "       'now', 'get', 'new', 'via', 'more', 'or', 'about', 'what', 'he',\n",
       "       'one', 'been', 'news', 'dont', 'they', 'over', 'who', 'were',\n",
       "       'people', 'how', 'into', 'us', '2', 'emergency', 'do', 'video',\n",
       "       'there', 'can', 'disaster', 'police', 'would', 'still', 'than',\n",
       "       'burning', 'his', 'california', 'her', 'crash', 'back', 'body',\n",
       "       'some', 'off', 'suicide', 'first', 'storm', 'got', 'why', 'cant',\n",
       "       'buildings', 'rt', 'going', 'fires', 'know'], dtype='<U17')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9446cce5",
   "metadata": {},
   "source": [
    "First let us check a bidirectional LSTM model with 64 units followed by a dense layer with 64 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4726045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm_1 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6315dda8",
   "metadata": {},
   "source": [
    "Here is a funtion to train the model. Early stopping is used to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "022f910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, lr=1e-4, epochs=20):\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=tf.keras.optimizers.Adam(lr),\n",
    "              metrics=['accuracy'])\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=5,mode=\"min\", restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    validation_steps=30, callbacks = [callback])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938eb4e0",
   "metadata": {},
   "source": [
    "First, find the optimal learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3cf126be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "179/179 [==============================] - 10s 30ms/step - loss: 0.5514 - accuracy: 0.7145 - val_loss: 0.4745 - val_accuracy: 0.7794\n",
      "Epoch 2/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.4150 - accuracy: 0.8166 - val_loss: 0.4628 - val_accuracy: 0.7857\n",
      "Epoch 3/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3729 - accuracy: 0.8431 - val_loss: 0.4761 - val_accuracy: 0.7946\n",
      "Epoch 4/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3333 - accuracy: 0.8604 - val_loss: 0.4955 - val_accuracy: 0.7925\n",
      "Epoch 5/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.2951 - accuracy: 0.8837 - val_loss: 0.5501 - val_accuracy: 0.7805\n",
      "Epoch 6/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.2560 - accuracy: 0.9026 - val_loss: 0.6268 - val_accuracy: 0.7700\n",
      "Epoch 7/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.2234 - accuracy: 0.9119 - val_loss: 0.6757 - val_accuracy: 0.7605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x128d1eca190>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model_lstm_1, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f036a841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "179/179 [==============================] - 10s 28ms/step - loss: 0.6867 - accuracy: 0.5624 - val_loss: 0.6739 - val_accuracy: 0.5814\n",
      "Epoch 2/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6367 - accuracy: 0.6590 - val_loss: 0.5594 - val_accuracy: 0.7784\n",
      "Epoch 3/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.5011 - accuracy: 0.7916 - val_loss: 0.4888 - val_accuracy: 0.7899\n",
      "Epoch 4/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.4395 - accuracy: 0.8224 - val_loss: 0.4710 - val_accuracy: 0.7967\n",
      "Epoch 5/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.4147 - accuracy: 0.8332 - val_loss: 0.4616 - val_accuracy: 0.7988\n",
      "Epoch 6/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3962 - accuracy: 0.8403 - val_loss: 0.4560 - val_accuracy: 0.8020\n",
      "Epoch 7/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3842 - accuracy: 0.8452 - val_loss: 0.4660 - val_accuracy: 0.7957\n",
      "Epoch 8/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3741 - accuracy: 0.8481 - val_loss: 0.4611 - val_accuracy: 0.7994\n",
      "Epoch 9/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3626 - accuracy: 0.8536 - val_loss: 0.4672 - val_accuracy: 0.8025\n",
      "Epoch 10/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3567 - accuracy: 0.8548 - val_loss: 0.4725 - val_accuracy: 0.7999\n",
      "Epoch 11/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3497 - accuracy: 0.8595 - val_loss: 0.4799 - val_accuracy: 0.7952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x128be7490d0>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model_lstm_1, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8fa3ff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "179/179 [==============================] - 10s 27ms/step - loss: 0.6919 - accuracy: 0.5665 - val_loss: 0.6908 - val_accuracy: 0.5809\n",
      "Epoch 2/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6905 - accuracy: 0.5705 - val_loss: 0.6890 - val_accuracy: 0.5814\n",
      "Epoch 3/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6888 - accuracy: 0.5666 - val_loss: 0.6869 - val_accuracy: 0.5814\n",
      "Epoch 4/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6871 - accuracy: 0.5666 - val_loss: 0.6848 - val_accuracy: 0.5814\n",
      "Epoch 5/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6852 - accuracy: 0.5666 - val_loss: 0.6825 - val_accuracy: 0.5814\n",
      "Epoch 6/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6832 - accuracy: 0.5666 - val_loss: 0.6799 - val_accuracy: 0.5814\n",
      "Epoch 7/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6809 - accuracy: 0.5668 - val_loss: 0.6773 - val_accuracy: 0.5819\n",
      "Epoch 8/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6782 - accuracy: 0.5726 - val_loss: 0.6740 - val_accuracy: 0.5872\n",
      "Epoch 9/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6748 - accuracy: 0.5779 - val_loss: 0.6699 - val_accuracy: 0.5914\n",
      "Epoch 10/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6702 - accuracy: 0.5856 - val_loss: 0.6645 - val_accuracy: 0.6056\n",
      "Epoch 11/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6637 - accuracy: 0.6029 - val_loss: 0.6575 - val_accuracy: 0.6187\n",
      "Epoch 12/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6542 - accuracy: 0.6195 - val_loss: 0.6466 - val_accuracy: 0.6423\n",
      "Epoch 13/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6408 - accuracy: 0.6609 - val_loss: 0.6314 - val_accuracy: 0.6744\n",
      "Epoch 14/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6225 - accuracy: 0.6975 - val_loss: 0.6130 - val_accuracy: 0.7201\n",
      "Epoch 15/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6010 - accuracy: 0.7479 - val_loss: 0.5924 - val_accuracy: 0.7400\n",
      "Epoch 16/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.5803 - accuracy: 0.7616 - val_loss: 0.5757 - val_accuracy: 0.7605\n",
      "Epoch 17/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.5615 - accuracy: 0.7754 - val_loss: 0.5609 - val_accuracy: 0.7705\n",
      "Epoch 18/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.5456 - accuracy: 0.7784 - val_loss: 0.5518 - val_accuracy: 0.7631\n",
      "Epoch 19/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.5320 - accuracy: 0.7824 - val_loss: 0.5406 - val_accuracy: 0.7663\n",
      "Epoch 20/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.5207 - accuracy: 0.7854 - val_loss: 0.5354 - val_accuracy: 0.7642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x128ef005fa0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model_lstm_1, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "518745b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "179/179 [==============================] - 11s 27ms/step - loss: 0.6876 - accuracy: 0.5610 - val_loss: 0.6762 - val_accuracy: 0.5825\n",
      "Epoch 2/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6446 - accuracy: 0.6476 - val_loss: 0.5620 - val_accuracy: 0.7679\n",
      "Epoch 3/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.5037 - accuracy: 0.7900 - val_loss: 0.4794 - val_accuracy: 0.7962\n",
      "Epoch 4/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.4428 - accuracy: 0.8199 - val_loss: 0.4663 - val_accuracy: 0.7994\n",
      "Epoch 5/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.4136 - accuracy: 0.8331 - val_loss: 0.4545 - val_accuracy: 0.8025\n",
      "Epoch 6/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3966 - accuracy: 0.8399 - val_loss: 0.4586 - val_accuracy: 0.8030\n",
      "Epoch 7/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3822 - accuracy: 0.8464 - val_loss: 0.4569 - val_accuracy: 0.8046\n",
      "Epoch 8/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3719 - accuracy: 0.8506 - val_loss: 0.4624 - val_accuracy: 0.8088\n",
      "Epoch 9/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3660 - accuracy: 0.8529 - val_loss: 0.4651 - val_accuracy: 0.7988\n",
      "Epoch 10/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3579 - accuracy: 0.8588 - val_loss: 0.4824 - val_accuracy: 0.7973\n"
     ]
    }
   ],
   "source": [
    "# retrain with the best learning rate\n",
    "history_1 = train_model(model_lstm_1, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c9889e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change parameters by adding more units to LSTM\n",
    "model_lstm_2 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=128,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ae3db8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "179/179 [==============================] - 11s 29ms/step - loss: 0.6798 - accuracy: 0.5772 - val_loss: 0.6411 - val_accuracy: 0.7048\n",
      "Epoch 2/20\n",
      "179/179 [==============================] - 3s 18ms/step - loss: 0.5460 - accuracy: 0.7648 - val_loss: 0.4903 - val_accuracy: 0.7815\n",
      "Epoch 3/20\n",
      "179/179 [==============================] - 3s 18ms/step - loss: 0.4485 - accuracy: 0.8124 - val_loss: 0.4661 - val_accuracy: 0.7915\n",
      "Epoch 4/20\n",
      "179/179 [==============================] - 3s 19ms/step - loss: 0.4115 - accuracy: 0.8299 - val_loss: 0.4625 - val_accuracy: 0.7883\n",
      "Epoch 5/20\n",
      "179/179 [==============================] - 3s 18ms/step - loss: 0.3895 - accuracy: 0.8383 - val_loss: 0.4731 - val_accuracy: 0.7967\n",
      "Epoch 6/20\n",
      "179/179 [==============================] - 3s 19ms/step - loss: 0.3753 - accuracy: 0.8457 - val_loss: 0.4746 - val_accuracy: 0.7941\n",
      "Epoch 7/20\n",
      "179/179 [==============================] - 3s 18ms/step - loss: 0.3637 - accuracy: 0.8522 - val_loss: 0.4680 - val_accuracy: 0.7978\n",
      "Epoch 8/20\n",
      "179/179 [==============================] - 3s 18ms/step - loss: 0.3501 - accuracy: 0.8543 - val_loss: 0.4830 - val_accuracy: 0.7915\n",
      "Epoch 9/20\n",
      "179/179 [==============================] - 3s 18ms/step - loss: 0.3449 - accuracy: 0.8600 - val_loss: 0.4950 - val_accuracy: 0.7910\n"
     ]
    }
   ],
   "source": [
    "history_2 = train_model(model_lstm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "68a9552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding more units to dense layer\n",
    "model_lstm_3 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d6415411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "179/179 [==============================] - 10s 27ms/step - loss: 0.6859 - accuracy: 0.5672 - val_loss: 0.6702 - val_accuracy: 0.5961\n",
      "Epoch 2/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.5929 - accuracy: 0.7056 - val_loss: 0.5169 - val_accuracy: 0.7600\n",
      "Epoch 3/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.4696 - accuracy: 0.7993 - val_loss: 0.4750 - val_accuracy: 0.7820\n",
      "Epoch 4/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.4238 - accuracy: 0.8205 - val_loss: 0.4572 - val_accuracy: 0.7952\n",
      "Epoch 5/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3986 - accuracy: 0.8318 - val_loss: 0.4546 - val_accuracy: 0.7983\n",
      "Epoch 6/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3802 - accuracy: 0.8401 - val_loss: 0.4572 - val_accuracy: 0.8025\n",
      "Epoch 7/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3672 - accuracy: 0.8446 - val_loss: 0.4622 - val_accuracy: 0.8036\n",
      "Epoch 8/20\n",
      "179/179 [==============================] - 3s 16ms/step - loss: 0.3554 - accuracy: 0.8529 - val_loss: 0.4723 - val_accuracy: 0.7946\n",
      "Epoch 9/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3472 - accuracy: 0.8550 - val_loss: 0.4889 - val_accuracy: 0.7931\n",
      "Epoch 10/20\n",
      "179/179 [==============================] - 3s 16ms/step - loss: 0.3400 - accuracy: 0.8569 - val_loss: 0.4916 - val_accuracy: 0.7925\n"
     ]
    }
   ],
   "source": [
    "history_3 = train_model(model_lstm_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a09adec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "179/179 [==============================] - 10s 27ms/step - loss: 0.6853 - accuracy: 0.5665 - val_loss: 0.6706 - val_accuracy: 0.5814\n",
      "Epoch 2/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.6342 - accuracy: 0.6625 - val_loss: 0.5777 - val_accuracy: 0.7721\n",
      "Epoch 3/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.5285 - accuracy: 0.7900 - val_loss: 0.5063 - val_accuracy: 0.7763\n",
      "Epoch 4/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.4545 - accuracy: 0.8154 - val_loss: 0.4786 - val_accuracy: 0.7836\n",
      "Epoch 5/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.4230 - accuracy: 0.8283 - val_loss: 0.4658 - val_accuracy: 0.7978\n",
      "Epoch 6/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.4014 - accuracy: 0.8389 - val_loss: 0.4670 - val_accuracy: 0.7920\n",
      "Epoch 7/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3861 - accuracy: 0.8453 - val_loss: 0.4775 - val_accuracy: 0.7862\n",
      "Epoch 8/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3745 - accuracy: 0.8513 - val_loss: 0.4646 - val_accuracy: 0.8004\n",
      "Epoch 9/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3666 - accuracy: 0.8551 - val_loss: 0.4784 - val_accuracy: 0.7962\n",
      "Epoch 10/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3555 - accuracy: 0.8548 - val_loss: 0.4775 - val_accuracy: 0.7957\n",
      "Epoch 11/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3492 - accuracy: 0.8595 - val_loss: 0.4836 - val_accuracy: 0.7915\n",
      "Epoch 12/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3393 - accuracy: 0.8637 - val_loss: 0.4868 - val_accuracy: 0.7941\n",
      "Epoch 13/20\n",
      "179/179 [==============================] - 3s 17ms/step - loss: 0.3320 - accuracy: 0.8681 - val_loss: 0.4957 - val_accuracy: 0.7904\n"
     ]
    }
   ],
   "source": [
    "#reducing units in dense layer\n",
    "model_lstm_4 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "history_4 = train_model(model_lstm_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b50f6e",
   "metadata": {},
   "source": [
    "Summary of LSTM models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87ac17",
   "metadata": {},
   "source": [
    "|model name| units in LSTM | units in dense layer| validation accuracy|\n",
    "|---|---|---|---|\n",
    "|model_lstm_1|64|64|0.8088|\n",
    "|model_lstm_2|128|64| 0.7978|\n",
    "|model_lstm_3|64|128|0.8036|\n",
    "|model_lstm_4|64|32|0.8004|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488b9d2c",
   "metadata": {},
   "source": [
    "Now try the GRU architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e24d84de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "179/179 [==============================] - 9s 25ms/step - loss: 0.6842 - accuracy: 0.5663 - val_loss: 0.6737 - val_accuracy: 0.5814\n",
      "Epoch 2/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.6404 - accuracy: 0.6285 - val_loss: 0.5841 - val_accuracy: 0.7216\n",
      "Epoch 3/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.4959 - accuracy: 0.7872 - val_loss: 0.4783 - val_accuracy: 0.7889\n",
      "Epoch 4/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.4234 - accuracy: 0.8210 - val_loss: 0.4643 - val_accuracy: 0.7920\n",
      "Epoch 5/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3987 - accuracy: 0.8275 - val_loss: 0.4666 - val_accuracy: 0.7836\n",
      "Epoch 6/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3795 - accuracy: 0.8385 - val_loss: 0.4806 - val_accuracy: 0.7778\n",
      "Epoch 7/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3677 - accuracy: 0.8474 - val_loss: 0.4691 - val_accuracy: 0.7862\n",
      "Epoch 8/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3593 - accuracy: 0.8494 - val_loss: 0.4753 - val_accuracy: 0.7820\n",
      "Epoch 9/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3536 - accuracy: 0.8539 - val_loss: 0.4802 - val_accuracy: 0.7868\n"
     ]
    }
   ],
   "source": [
    "model_gru_1 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "history_gru1 = train_model(model_gru_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "30218729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "179/179 [==============================] - 10s 27ms/step - loss: 0.6804 - accuracy: 0.5689 - val_loss: 0.6619 - val_accuracy: 0.5924\n",
      "Epoch 2/20\n",
      "179/179 [==============================] - 3s 16ms/step - loss: 0.5696 - accuracy: 0.7246 - val_loss: 0.5120 - val_accuracy: 0.7579\n",
      "Epoch 3/20\n",
      "179/179 [==============================] - 3s 16ms/step - loss: 0.4438 - accuracy: 0.8078 - val_loss: 0.4849 - val_accuracy: 0.7721\n",
      "Epoch 4/20\n",
      "179/179 [==============================] - 3s 16ms/step - loss: 0.4031 - accuracy: 0.8283 - val_loss: 0.4909 - val_accuracy: 0.7726\n",
      "Epoch 5/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3808 - accuracy: 0.8390 - val_loss: 0.4780 - val_accuracy: 0.7820\n",
      "Epoch 6/20\n",
      "179/179 [==============================] - 3s 16ms/step - loss: 0.3671 - accuracy: 0.8422 - val_loss: 0.4740 - val_accuracy: 0.7857\n",
      "Epoch 7/20\n",
      "179/179 [==============================] - 3s 16ms/step - loss: 0.3591 - accuracy: 0.8471 - val_loss: 0.4990 - val_accuracy: 0.7763\n",
      "Epoch 8/20\n",
      "179/179 [==============================] - 3s 16ms/step - loss: 0.3477 - accuracy: 0.8523 - val_loss: 0.5027 - val_accuracy: 0.7736\n",
      "Epoch 9/20\n",
      "179/179 [==============================] - 3s 16ms/step - loss: 0.3378 - accuracy: 0.8550 - val_loss: 0.5064 - val_accuracy: 0.7736\n",
      "Epoch 10/20\n",
      "179/179 [==============================] - 3s 16ms/step - loss: 0.3288 - accuracy: 0.8606 - val_loss: 0.5525 - val_accuracy: 0.7563\n",
      "Epoch 11/20\n",
      "179/179 [==============================] - 3s 16ms/step - loss: 0.3204 - accuracy: 0.8655 - val_loss: 0.5388 - val_accuracy: 0.7626\n"
     ]
    }
   ],
   "source": [
    "model_gru_2 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=128,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "history_gru2 = train_model(model_gru_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "99b56c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "179/179 [==============================] - 10s 25ms/step - loss: 0.6859 - accuracy: 0.5623 - val_loss: 0.6754 - val_accuracy: 0.5814\n",
      "Epoch 2/20\n",
      "179/179 [==============================] - 3s 14ms/step - loss: 0.6489 - accuracy: 0.6255 - val_loss: 0.5785 - val_accuracy: 0.7390\n",
      "Epoch 3/20\n",
      "179/179 [==============================] - 3s 14ms/step - loss: 0.4893 - accuracy: 0.7840 - val_loss: 0.4900 - val_accuracy: 0.7763\n",
      "Epoch 4/20\n",
      "179/179 [==============================] - 3s 14ms/step - loss: 0.4273 - accuracy: 0.8164 - val_loss: 0.4698 - val_accuracy: 0.7768\n",
      "Epoch 5/20\n",
      "179/179 [==============================] - 3s 14ms/step - loss: 0.3992 - accuracy: 0.8329 - val_loss: 0.4703 - val_accuracy: 0.7883\n",
      "Epoch 6/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3829 - accuracy: 0.8353 - val_loss: 0.4662 - val_accuracy: 0.7841\n",
      "Epoch 7/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3676 - accuracy: 0.8459 - val_loss: 0.4724 - val_accuracy: 0.7862\n",
      "Epoch 8/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3572 - accuracy: 0.8488 - val_loss: 0.5101 - val_accuracy: 0.7700\n",
      "Epoch 9/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3480 - accuracy: 0.8530 - val_loss: 0.5130 - val_accuracy: 0.7700\n",
      "Epoch 10/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3409 - accuracy: 0.8576 - val_loss: 0.5107 - val_accuracy: 0.7773\n",
      "Epoch 11/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3351 - accuracy: 0.8590 - val_loss: 0.5190 - val_accuracy: 0.7673\n"
     ]
    }
   ],
   "source": [
    "model_gru_3 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "history_gru3 = train_model(model_gru_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "91470d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "179/179 [==============================] - 10s 25ms/step - loss: 0.6871 - accuracy: 0.5582 - val_loss: 0.6763 - val_accuracy: 0.5814\n",
      "Epoch 2/20\n",
      "179/179 [==============================] - 3s 14ms/step - loss: 0.6538 - accuracy: 0.6178 - val_loss: 0.5983 - val_accuracy: 0.7279\n",
      "Epoch 3/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.5137 - accuracy: 0.7819 - val_loss: 0.5135 - val_accuracy: 0.7458\n",
      "Epoch 4/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.4380 - accuracy: 0.8129 - val_loss: 0.4727 - val_accuracy: 0.7862\n",
      "Epoch 5/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.4066 - accuracy: 0.8310 - val_loss: 0.4725 - val_accuracy: 0.7868\n",
      "Epoch 6/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3916 - accuracy: 0.8362 - val_loss: 0.4638 - val_accuracy: 0.7925\n",
      "Epoch 7/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3761 - accuracy: 0.8439 - val_loss: 0.4647 - val_accuracy: 0.7857\n",
      "Epoch 8/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3685 - accuracy: 0.8438 - val_loss: 0.4776 - val_accuracy: 0.7831\n",
      "Epoch 9/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3585 - accuracy: 0.8495 - val_loss: 0.4748 - val_accuracy: 0.7910\n",
      "Epoch 10/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3519 - accuracy: 0.8508 - val_loss: 0.4805 - val_accuracy: 0.7868\n",
      "Epoch 11/20\n",
      "179/179 [==============================] - 3s 15ms/step - loss: 0.3445 - accuracy: 0.8553 - val_loss: 0.4844 - val_accuracy: 0.7915\n"
     ]
    }
   ],
   "source": [
    "model_gru_4 = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "history_gru4 = train_model(model_gru_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818f4bb",
   "metadata": {},
   "source": [
    "Summary of GRU models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158e8836",
   "metadata": {},
   "source": [
    "|model name| units in LSTM | units in dense layer| validation accuracy|\n",
    "|---|---|---|---|\n",
    "|model_gru_1|64|64|0.7920|\n",
    "|model_gru_2|128|64| 0.7857|\n",
    "|model_gru_3|64|128|0.7883|\n",
    "|model_gru_4|64|32|0.7925|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4da0b19",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Overall I find the LSTM model 1 performs slightly better. Also I noticed that changing model architecture has very limited impact on the validation accuracy. So the bottleneck might be data preprocessing. Using preprocessing techniques such as lemmatization might further improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fae2fe",
   "metadata": {},
   "source": [
    "## Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "24a82bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test['processed_text'] = df_test['text'].str.replace('@\\w* ', '', case=False, regex=True)\n",
    "df_test['processed_text'] = df_test['processed_text'].str.replace('http[^\\s]*', '', case=False, regex=True)\n",
    "df_test['processed_text'] = df_test['processed_text'].str.replace('[^\\w\\s]', '', regex=True)\n",
    "df_test['processed_text'] = df_test['processed_text'].str.lower()\n",
    "X_test = tf.convert_to_tensor(df_test['processed_text'])\n",
    "yprob_test = model_lstm_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "344e62db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       0\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yclass_test = np.zeros_like(yprob_test)\n",
    "yclass_test[yprob_test>0.5] = 1\n",
    "yclass_test = yclass_test.astype(np.int32).reshape([-1])\n",
    "ids = df_test['id'].to_numpy()\n",
    "submission_df = pd.DataFrame(np.array([ids, yclass_test]).T, columns=['id', 'target'])\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "09028ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d73078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
